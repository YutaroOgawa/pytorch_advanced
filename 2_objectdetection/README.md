## 物体検出とは
- 物体検出とは、何をインプットに何をアウトプットするタスクなのか理解する
    - 物体検出：画像内の複数の物体に対して、物体の領域と物体名を特定するタスク
        - インプット：画像
        - アウトプット：
            1. 物体の位置を示す枠（バウンディングボックス=Bounding Box）の位置と大きさ
            2. 各バウンディングボックスのラベル情報（物体名）
            3. 検出の信頼度=confidence（最大1.00）
        - バウンディングボックスの表現方法は２通り
            - 長方形の左上座標(xmin, ymin)と右下座標(xmax, ymax)を指定
            - 中心座標(cx, cy)、幅w、高さhで指定
        - 物体のクラス数O + 背景クラス = (O+1)種類のクラスから、各バウンディングボックスにつき信頼度が最大となるラベルを出力
- VOCデータセットについて理解する
    - VOCデータセットとは：物体検出コンテストで使用されたデータセット
    - VOC2010データセットの概要：
        - クラス20種類+背景1種類、訓練データ5,717枚、検証データ5,823枚
        - 各画像には(xmin, ymin, xmax, ymax)と、物体クラスのアノテーションデータ（xml形式）が提供
- SSDによる物体検出の6stepの流れを理解する
    - SSDでは、あらかじめ用意した定型的な長方形（デフォルトボックス）をバウンディングボックスに変形させるための変化量情報（オフセット情報）を出力する。
    （画像内でwindowをスライドさせて検出するRCNN系の手法とは発想が異なる。1度のCNN演算で検出できるためSSDのほうがより高速だが、精度は若干落ちる。）
    1. 画像をリサイズ（SSD300の場合は300×300ピクセル）+ 色情報の標準化
    2. デフォルトボックスを用意（SSD300の場合は8,732個）
    3. 画像をSSDのネットワークに入力。出力=デフォルトボックス8,732個×(各クラスの信頼度:21個 + オフセット:４変数)
    4. 信頼度上位のデフォルトボックスを複数個抽出（SSD300の場合はtop200。各デフォルトボックスの最大の信頼度で比較。）
    5. オフセット情報による修正と被りの除去（同じ物体を検出していると思われるものが複数ある場合は、最も信頼度が高いバウンディングボックスだけ残す）
    6. 一定の信頼度以上のものを最終出力とする（閾値の高さで誤検出や未検出を調整）

## Datasetの実装
- 物体検出で使用するDatasetクラスを作成できるようになる
    - バウンディングボックス（BBox）の情報を、画像の幅もしくは高さで割り算して座標を規格化
    - アノテーション情報は画像ごとにリスト型で返す（要素数はその画像内の物体数、各要素はBBoxの座標とクラスラベル=5変数）

- SSDの学習時のデータオーギュメンテーションで、何をしているのかを理解する
    - 画像の変形時にBBoxも同時に変形する必要がある
    - SSD300のデータオーギュメンテーション：色調のランダム変化、キャンバスの拡大、ランダム切り出し、ランダム反転
        - ランダム切り出し時は、少なくとも一つのGround-Truthボックス(GTBox)と切り出し画像がオーバラップし、GTBoxの中心座標が切り出し画像内に含まれるようにする（切り出した画像に物体が存在しないと、データオーギュメンテーションの意味がないため）。
        参考：https://www.telesens.co/2018/06/28/data-augmentation-in-ssd/

## DataLoaderの実装
- 物体検出で使用するDataLoaderクラス（ミニバッチとしてデータを取り出すクラス）を作成できるようになる
    - 画像ごとにアノテーション情報のサイズ（画像内の物体数）が異なることに注意

## ネットワークモデルの実装
- SSDのネットワークモデルを構築している４つのモジュールを把握する
    - vgg, extras, loc, conf
    - vggとextrasの出力が、locとconfにそれぞれ入力され、デフォルトボックスのオフセット及びクラス信頼度がそれぞれ出力される
    - SSDでは6つの異なるサイズの特徴量マップを利用することで、様々な大きさの物体を想定した特徴量が学習できる
    - サイズが大きいsource1の特徴量マップ（すなわち小さい物体に着目する）が他の特徴量マップよりも畳み込み回数が少ないため、小さな物体の検出が苦手。
- SSDのネットワークモデルを作成できるようになる
    - locとconfでは、入力に応じてどのレイヤーに流すかを順伝搬の実装で定義
    - L2Norm層ではチャネル方向にセルの値を正規化し、学習パラメータとなる係数をチャネルごとにかける
- SSDで使用する様々な大きさのデフォルトボックス（DBox）の実装方法を理解する
    - 各特徴量マップの各セルごとに、複数のDBoxを用意（サイズが異なる正方形や長方形）
    - 実装時は特徴量マップのサイズに合わせてproduct()で全組み合わせを取得し、それぞれDBoxを定義

## 順伝搬関数の実装
- Non-Maximum Suppressionを理解する
    - BBoxの被りを除去する処理のこと。BBox同士のかぶっている面積の比率（IoU）が閾値以上の場合は冗長と判定し、クラスの確信度confが一番大きなBBoxのみ残す（この処理は物体クラスごとに行う）。
    1. 確信度上位200個のBBoxを取り出す。
    2. 確信度が最大のBBoxを対象BBoxとする。
    3. 対象BBoxと残りのBBoxとでIoUを計算し、IoUが閾値以上だったBBoxは消去する（確信度最大BBoxと同じ物体を検出しているから）。
    4. 残っているBBoxで2.~3.を繰り返す。BBoxが最後の１個になったら終了。
- SSDの推論時に使用するDetectクラスの順伝搬を理解する
    - 入力：オフセット情報=locの出力(batch_num, 8732, 4)、確信度=confの出力(batch_num, 8732, 21)、DBoxの情報(8732, 4)
    - 出力：(batch_num, 21, 200, 5)
        - batch_num: ミニバッチ番号を示す次元
        - 21: 各クラスのインデックスを示す次元
        - 200: 上位200のBBoxの番号を示す次元
        - 5: BBoxの情報（確信度conf, xmin, ymin, width, height）
    1. DBox情報とオフセット情報から、BBoxを計算
    2. confが閾値以上のBBoxを取り出す（全てのBBox=8,732個に対して3.を計算すると処理が重いため）
    3. Non-Maximum Suppressionを実施して、検出物体が被っているBBoxを消去
- SSDの順伝搬を実装できるようになる

## 損失関数の実装
- jaccard係数(=IoU: Intersection over Union)を用いたmatch関数の動作を理解する
    - jaccard係数=(A∩B)/(A∪B): 2つのBoxの被っている面積の割合
    - match関数：jaccard係数を使ってGround-Truthボックス(GTBox)と近いDBoxを抽出する関数。すなわち、各DBoxの教師データを作成。
    - jaccard係数>=0.5となるGTBoxを持つDBox = Positive DBox
        - jaccard係数最大のGTBoxの物体クラス = そのDBoxの物体クラスの教師データ
        - jaccard係数最大のGTBoxへDBoxを変形させるオフセット値 = locの教師データ
    - jaccard係数>=0.5となるGTBoxを持たないDBox = Negative DBox
        - 背景をそのDBoxの教師データとする

- Hard Negative Miningを理解する
    - 学習に使用するNegative DBoxを絞る操作のこと
    - 背景クラスのデータの比率が非常に高くなるので、Negative DBoxの数をPositive DBoxの一定数倍に数を絞る
    - 残すのはラベル予測の損失値が高いNegative DBox（背景クラスなのに物体が存在すると予測したデータを優先的に学習する）

- 2種類の損失関数（SmoothL1Loss関数、交差エントロピー誤差関数）の働きを理解する
    - オフセット情報の予測の損失関数：
        - 補正値を予測する回帰問題 -> SmoothL1Loss関数を利用(予測値と正解値の差が大きい場合に損失を小さく見積もることで、ネットワークの学習を安定化させる手法)
        - Positive DBoxの予測結果にのみ計算
    - 物体クラスの予測の損失関数：
        - クラス分類問題 -> 交差エントロピー誤差関数

## 学習と検証の実施
- SSDの学習を実装できるようになる
    - 学習プログラムの流れ
        1. DataLoaderの作成
        2. ネットワークモデルの作成
        3. 損失関数の定義
        4. 最適化手法の設定
        5. 学習・検証の実施

## 推論の実施
- SSDの推論を実装できるようになる
    - 推論の流れ
        1. SSDモデルを組み立て、学習済みパラメータをロード
        2. 画像を読み込み、前処理を適用して、SSDモデルで推論

